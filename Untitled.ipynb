{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. Let's say we want to compete on Jeopardy, and we're looking for any edge we can get to win. In this project we will figure out some patterns in the questions that could help us win.\n",
    "\n",
    "At first we import dataset which contains around 200000 rows of Jeopardy questions from it's beginning from CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import dataset from file\n",
    "jeopardy = pd.read_csv('JEOPARDY_CSV.csv')\n",
    "\n",
    "# show first 5 rows of dataset\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of dataset column names have spaces in front of their column names. Let's delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ShowNumber', 'AirDate', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign column names with deleted spaces to variable\n",
    "jeopardy_columns = jeopardy.columns.str.replace(' ', '')\n",
    "# assign variable's values to column names back\n",
    "jeopardy.columns = jeopardy_columns\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also convert *Value* column to integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$200' '$400' '$600' '$800' '$2,000' '$1000' '$1200' '$1600' '$2000'\n",
      " '$3,200' 'None' '$5,000' '$100' '$300' '$500' '$1,000' '$1,500' '$1,200'\n",
      " '$4,800' '$1,800' '$1,100' '$2,200' '$3,400' '$3,000' '$4,000' '$1,600'\n",
      " '$6,800' '$1,900' '$3,100' '$700' '$1,400' '$2,800' '$8,000' '$6,000'\n",
      " '$2,400' '$12,000' '$3,800' '$2,500' '$6,200' '$10,000' '$7,000' '$1,492'\n",
      " '$7,400' '$1,300' '$7,200' '$2,600' '$3,300' '$5,400' '$4,500' '$2,100'\n",
      " '$900' '$3,600' '$2,127' '$367' '$4,400' '$3,500' '$2,900' '$3,900'\n",
      " '$4,100' '$4,600' '$10,800' '$2,300' '$5,600' '$1,111' '$8,200' '$5,800'\n",
      " '$750' '$7,500' '$1,700' '$9,000' '$6,100' '$1,020' '$4,700' '$2,021'\n",
      " '$5,200' '$3,389' '$4,200' '$5' '$2,001' '$1,263' '$4,637' '$3,201'\n",
      " '$6,600' '$3,700' '$2,990' '$5,500' '$14,000' '$2,700' '$6,400' '$350'\n",
      " '$8,600' '$6,300' '$250' '$3,989' '$8,917' '$9,500' '$1,246' '$6,435'\n",
      " '$8,800' '$2,222' '$2,746' '$10,400' '$7,600' '$6,700' '$5,100' '$13,200'\n",
      " '$4,300' '$1,407' '$12,400' '$5,401' '$7,800' '$1,183' '$1,203' '$13,000'\n",
      " '$11,600' '$14,200' '$1,809' '$8,400' '$8,700' '$11,000' '$5,201'\n",
      " '$1,801' '$3,499' '$5,700' '$601' '$4,008' '$50' '$2,344' '$2,811'\n",
      " '$18,000' '$1,777' '$3,599' '$9,800' '$796' '$3,150' '$20' '$1,810' '$22'\n",
      " '$9,200' '$1,512' '$8,500' '$585' '$1,534' '$13,800' '$5,001' '$4,238'\n",
      " '$16,400' '$1,347' '$2547' '$11,200']\n"
     ]
    }
   ],
   "source": [
    "# show all unique values for Value column\n",
    "print(jeopardy['Value'].unique())\n",
    "\n",
    "# delete '$' and ',' symbol and None value from Value column\n",
    "jeopardy['Value'] = jeopardy['Value'].str.replace('$', '')\n",
    "jeopardy['Value'] = jeopardy['Value'].str.replace(',', '')\n",
    "jeopardy['Value'] = jeopardy['Value'].str.replace('None', '0')\n",
    "\n",
    "# convert Value column type to int\n",
    "jeopardy['Value'] = jeopardy['Value'].astype(int)\n",
    "\n",
    "jeopardy.rename({'Value': 'Value, $'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also convert *AirDate* column values from str to date type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216930 entries, 0 to 216929\n",
      "Data columns (total 7 columns):\n",
      "ShowNumber    216930 non-null int64\n",
      "AirDate       216930 non-null datetime64[ns]\n",
      "Round         216930 non-null object\n",
      "Category      216930 non-null object\n",
      "Value, $      216930 non-null int64\n",
      "Question      216930 non-null object\n",
      "Answer        216928 non-null object\n",
      "dtypes: datetime64[ns](1), int64(2), object(4)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# convert to datetime\n",
    "jeopardy['AirDate'] = pd.to_datetime(jeopardy['AirDate'])\n",
    "\n",
    "# show information about Jeopardy dataframe columns and their types \n",
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we normalize all questions it *Question* and *Answer* columns. To do that we write a function which will convert all word in string to lowercase and delete all punctuation symbols. Then we apply that function to *Question* and *Answer* columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShowNumber</th>\n",
       "      <th>AirDate</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value, $</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Clean Question</th>\n",
       "      <th>Clean Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ShowNumber    AirDate      Round                         Category  \\\n",
       "0        4680 2004-12-31  Jeopardy!                          HISTORY   \n",
       "1        4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   \n",
       "2        4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   \n",
       "3        4680 2004-12-31  Jeopardy!                 THE COMPANY LINE   \n",
       "4        4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   \n",
       "\n",
       "   Value, $                                           Question      Answer  \\\n",
       "0       200  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1       200  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2       200  The city of Yuma in this state has a record av...     Arizona   \n",
       "3       200  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4       200  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                      Clean Question Clean Answer  \n",
       "0  for the last 8 years of his life galileo was u...   copernicus  \n",
       "1  no 2 1912 olympian football star at carlisle i...   jim thorpe  \n",
       "2  the city of yuma in this state has a record av...      arizona  \n",
       "3  in 1963 live on the art linkletter show this c...    mcdonalds  \n",
       "4  signer of the dec of indep framer of the const...   john adams  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# define function which brings letter case of string to lower and delete all punctuation symbols \n",
    "def normalize(value):\n",
    "    value = value.lower()\n",
    "    return re.sub('[^a-z0-9\\s\\-]', '', value)\n",
    "    \n",
    "# apply function to Question column, assing result to new column Clean Question\n",
    "jeopardy['Clean Question'] = jeopardy['Question'].apply(normalize)\n",
    "\n",
    "# apply function to Answer column, assing result to new column Clean Answer\n",
    "jeopardy['Clean Answer'] = jeopardy['Answer'].astype(str).apply(normalize)\n",
    "\n",
    "# show first five rows of dataset\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we write a function which helps to figure out:\n",
    "\n",
    "* How often the answer is deducible from the question.\n",
    "* How often new questions are repeats of older questions.\n",
    "\n",
    "# Answers in questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05931971014221584"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_matches(row):\n",
    "    # variable which counts word matches in answer and question\n",
    "    match_count = 0\n",
    "    # split answer and question in a word lists for more convinient count\n",
    "    split_question = row['Clean Question'].split(' ')\n",
    "    split_answer = row['Clean Answer'].split(' ')\n",
    "    # delete from answer word 'the' as the most common\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    # if answer length is 0 - return 0 to prevent zero division\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    # else count word matches\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1\n",
    "    # divide number of matches by len of answer, return the result\n",
    "    return match_count/len(split_answer)\n",
    "\n",
    "# apply the function to new column Answer in Question\n",
    "jeopardy['Answer in Question'] = jeopardy.apply(count_matches, axis=1)\n",
    "\n",
    "# find a mean of Answer in Question column\n",
    "jeopardy['Answer in Question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean value for *Answer in Question* column is around 0.06. That means that vast majority of questions doesn't contain an answer in themselfs. That also means that we can't win the Jeopardy by looking for answer in question. We have to study.\n",
    "\n",
    "Now we want to answer how often new answers repeat the old ones. To do that we sort the dataset according to *Air Date* column dates from older to newer than write function which counts how often new questions repeat the old ones and apply that function to the entire dataset.\n",
    "\n",
    "# Questions overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8713278428096588"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort dataset by date from earliest to latest\n",
    "jeopardy = jeopardy.sort_values('AirDate')\n",
    "# set for storing words from answers\n",
    "terms_used = set()\n",
    "\n",
    "def count_repeats(row):\n",
    "    # variable which counts word repeats in answer\n",
    "    repeat_count = 0\n",
    "    # split answer in a word lists for more convinient count\n",
    "    split_question = row['Clean Question'].split(' ')\n",
    "    # delete from list any word which length less than 6 \n",
    "    split_question = [word for word in split_question if len(word) > 5]\n",
    "    # count question word repeats\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            repeat_count += 1\n",
    "        terms_used.add(word)\n",
    "    # divide number of repeats by length of question and add it to list\n",
    "    if len(split_question) > 0:\n",
    "        repeat_count /= len(split_question)\n",
    "    return repeat_count\n",
    "\n",
    "jeopardy['Questions Overlap'] = jeopardy.apply(count_repeats, axis=1)\n",
    "jeopardy['Questions Overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, of 87% words in average question was used before. This makes it relatively insignificant, but it does mean that it's worth looking more into the recycling of questions.\n",
    "\n",
    "We also find that *terms_used* set of words in questions has a strange words like *hrefhttpwwwj-archivecommedia*, etc. Let's delete these words from set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in list(terms_used):\n",
    "    if 'hrefhttpwwwj-archivecommedia' in term:\n",
    "        terms_used.remove(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to know if there are words which can be met in high value questions more often, than words with low value. Let's figure this out. At first we write a function that will determine which question has high value ($800 and more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShowNumber</th>\n",
       "      <th>AirDate</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value, $</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Clean Question</th>\n",
       "      <th>Clean Answer</th>\n",
       "      <th>Answer in Question</th>\n",
       "      <th>Questions Overlap</th>\n",
       "      <th>High Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84523</th>\n",
       "      <td>1</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>100</td>\n",
       "      <td>River mentioned most often in the Bible</td>\n",
       "      <td>the Jordan</td>\n",
       "      <td>river mentioned most often in the bible</td>\n",
       "      <td>the jordan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84565</th>\n",
       "      <td>1</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>THE BIBLE</td>\n",
       "      <td>1000</td>\n",
       "      <td>According to 1st Timothy, it is the \"root of a...</td>\n",
       "      <td>the love of money</td>\n",
       "      <td>according to 1st timothy it is the root of all...</td>\n",
       "      <td>the love of money</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84566</th>\n",
       "      <td>1</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>'50'S TV</td>\n",
       "      <td>1000</td>\n",
       "      <td>Name under which experimenter Don Herbert taug...</td>\n",
       "      <td>Mr. Wizard</td>\n",
       "      <td>name under which experimenter don herbert taug...</td>\n",
       "      <td>mr wizard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84567</th>\n",
       "      <td>1</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>NATIONAL LANDMARKS</td>\n",
       "      <td>1000</td>\n",
       "      <td>D.C. building shaken by November '83 bomb blast</td>\n",
       "      <td>the Capitol</td>\n",
       "      <td>dc building shaken by november 83 bomb blast</td>\n",
       "      <td>the capitol</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84568</th>\n",
       "      <td>1</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>NOTORIOUS</td>\n",
       "      <td>1000</td>\n",
       "      <td>After the deed, he leaped to the stage shoutin...</td>\n",
       "      <td>John Wilkes Booth</td>\n",
       "      <td>after the deed he leaped to the stage shouting...</td>\n",
       "      <td>john wilkes booth</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ShowNumber    AirDate             Round            Category  Value, $  \\\n",
       "84523           1 1984-09-10         Jeopardy!      LAKES & RIVERS       100   \n",
       "84565           1 1984-09-10  Double Jeopardy!           THE BIBLE      1000   \n",
       "84566           1 1984-09-10  Double Jeopardy!            '50'S TV      1000   \n",
       "84567           1 1984-09-10  Double Jeopardy!  NATIONAL LANDMARKS      1000   \n",
       "84568           1 1984-09-10  Double Jeopardy!           NOTORIOUS      1000   \n",
       "\n",
       "                                                Question             Answer  \\\n",
       "84523            River mentioned most often in the Bible         the Jordan   \n",
       "84565  According to 1st Timothy, it is the \"root of a...  the love of money   \n",
       "84566  Name under which experimenter Don Herbert taug...         Mr. Wizard   \n",
       "84567    D.C. building shaken by November '83 bomb blast        the Capitol   \n",
       "84568  After the deed, he leaped to the stage shoutin...  John Wilkes Booth   \n",
       "\n",
       "                                          Clean Question       Clean Answer  \\\n",
       "84523            river mentioned most often in the bible         the jordan   \n",
       "84565  according to 1st timothy it is the root of all...  the love of money   \n",
       "84566  name under which experimenter don herbert taug...          mr wizard   \n",
       "84567       dc building shaken by november 83 bomb blast        the capitol   \n",
       "84568  after the deed he leaped to the stage shouting...  john wilkes booth   \n",
       "\n",
       "       Answer in Question  Questions Overlap  High Value  \n",
       "84523            0.000000                0.0           0  \n",
       "84565            0.333333                0.0           1  \n",
       "84566            0.000000                0.0           1  \n",
       "84567            0.000000                0.0           1  \n",
       "84568            0.000000                0.0           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def high_value(value):\n",
    "    if value > 800:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "jeopardy['High Value'] = jeopardy['Value, $'].apply(high_value)\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we write a function which counts number of high and low question in which one or another word could be met. Counting frequencies for each word is an extremely huge task, so at first we count for first 10 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rabelais': [3, 8],\n",
       " 'nabopolassar': [1, 0],\n",
       " 'quarries': [1, 4],\n",
       " 'grumble': [2, 4],\n",
       " 'rasingingin': [0, 1],\n",
       " 'stretcht': [0, 1],\n",
       " 'secretaries-general': [2, 0],\n",
       " 'mazzello': [0, 1],\n",
       " 'targetblankmassacrea': [1, 0],\n",
       " 'roosts': [0, 1],\n",
       " 'apapane': [0, 1],\n",
       " 'targetblank100': [0, 1],\n",
       " 'elment': [0, 1],\n",
       " 'crystal-induced': [0, 1],\n",
       " 'keratin': [1, 6],\n",
       " 'openings': [4, 6],\n",
       " 'evinced': [0, 1],\n",
       " 'name--yep': [0, 1],\n",
       " 'panning': [0, 1],\n",
       " 'bonsal': [1, 0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparsion_dict = {k:[0, 0] for k in list(terms_used)[:20]}\n",
    "\n",
    "def count_high_low_value(row):\n",
    "    # split answer in a word lists for more convinient count\n",
    "    split_question = row['Clean Question'].split(' ')\n",
    "    # count question word repeats\n",
    "    for word in comparsion_dict.keys():\n",
    "        if word in split_question:\n",
    "            if row['High Value'] == 1:\n",
    "                comparsion_dict[word][0] += 1\n",
    "            else:\n",
    "                comparsion_dict[word][1] += 1\n",
    "\n",
    "jeopardy.apply(count_high_low_value, axis=1)\n",
    "comparsion_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we count the number of high and low value words in dataset and use these values for chisquared test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61422\n",
      "155508\n"
     ]
    }
   ],
   "source": [
    "high_value_count = jeopardy.loc[jeopardy['High Value'] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy['High Value'] == 0].shape[0]\n",
    "print(high_value_count)\n",
    "print(low_value_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time for chi-square testing. We will use values from our high/low value frequency dictionary and number of high and low words in dataset to build sets of observed and expected frequencies for each word in our dictionary and then we count chi-square values for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.005878321230796754, pvalue=0.9388859030670194),\n",
       " Power_divergenceResult(statistic=2.5317964247338085, pvalue=0.11157312838169751),\n",
       " Power_divergenceResult(statistic=0.1702839704934861, pvalue=0.6798595573662745),\n",
       " Power_divergenceResult(statistic=0.07446818777814278, pvalue=0.7849388502668134),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=5.063592849467617, pvalue=0.02443353405878706),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=2.5317964247338085, pvalue=0.11157312838169751),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.6787070195906365, pvalue=0.4100323130964867),\n",
       " Power_divergenceResult(statistic=0.6727895508141588, pvalue=0.41208073002848244),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=2.5317964247338085, pvalue=0.11157312838169751)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "chi_squared = list()\n",
    "\n",
    "# for every key in dict\n",
    "for key in comparsion_dict.keys():\n",
    "    # count sum of each dict element\n",
    "    total = sum(comparsion_dict[key])\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    # count expected high and low values for each word\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    # count observed high and low values for each word\n",
    "    observed = np.array([comparsion_dict[key][0], comparsion_dict[key][1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-squared results\n",
    "\n",
    "Some of the terms had a significant difference in usage between high value and low value rows, but only some. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies.\n",
    "\n",
    "Then we make a dictionary of popular words with frequencies more than 1000, where key is word, first value is total frequeuncy of that word in dataset, second value is frequency of that word in high value questions, third value is a frequency of that word in high value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'called': [5461, 1712, 3749],\n",
       " 'country': [4868, 1391, 3477],\n",
       " 'became': [3162, 915, 2247],\n",
       " 'played': [3011, 773, 2238],\n",
       " 'president': [3010, 845, 2165],\n",
       " 'before': [2909, 787, 2122],\n",
       " 'american': [2837, 925, 1912],\n",
       " 'capital': [2772, 803, 1969],\n",
       " 'famous': [2497, 721, 1776],\n",
       " 'french': [2488, 943, 1545],\n",
       " 'targetblankherea': [2469, 1065, 1404],\n",
       " 'island': [2445, 771, 1674],\n",
       " 'people': [2224, 603, 1621],\n",
       " 'during': [2000, 563, 1437],\n",
       " 'national': [1976, 571, 1405],\n",
       " 'british': [1947, 657, 1290],\n",
       " 'largest': [1943, 481, 1462],\n",
       " 'century': [1820, 642, 1178],\n",
       " 'little': [1812, 480, 1332],\n",
       " 'company': [1798, 498, 1300],\n",
       " 'around': [1797, 530, 1267],\n",
       " 'character': [1755, 510, 1245],\n",
       " 'author': [1692, 644, 1048],\n",
       " 'between': [1668, 540, 1128],\n",
       " 'targetblankthisa': [1623, 790, 833],\n",
       " 'series': [1619, 399, 1220],\n",
       " 'meaning': [1570, 580, 990],\n",
       " 'family': [1537, 482, 1055],\n",
       " 'founded': [1486, 482, 1004],\n",
       " 'include': [1409, 360, 1049],\n",
       " 'states': [1375, 366, 1009],\n",
       " 'number': [1316, 330, 986],\n",
       " 'million': [1308, 334, 974],\n",
       " 'musical': [1307, 413, 894],\n",
       " 'school': [1298, 396, 902],\n",
       " 'popular': [1286, 341, 945],\n",
       " 'english': [1279, 424, 855],\n",
       " 'museum': [1270, 336, 934],\n",
       " 'because': [1269, 365, 904],\n",
       " 'classic': [1259, 334, 925],\n",
       " 'through': [1239, 378, 861],\n",
       " 'reports': [1235, 539, 696],\n",
       " 'university': [1213, 365, 848],\n",
       " 'countrys': [1135, 259, 876],\n",
       " 'george': [1129, 336, 793],\n",
       " 'person': [1095, 275, 820],\n",
       " 'father': [1092, 338, 754],\n",
       " 'german': [1072, 427, 645],\n",
       " 'created': [1037, 307, 730],\n",
       " 'leader': [1031, 339, 692],\n",
       " 'america': [1029, 283, 746],\n",
       " 'william': [1024, 319, 705],\n",
       " 'former': [1020, 303, 717],\n",
       " 'general': [1005, 304, 701],\n",
       " 'italian': [1004, 423, 581],\n",
       " 'second': [1004, 296, 708]}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = dict()\n",
    "\n",
    "def count_terms_freq(row):\n",
    "    # split answer in a word lists for more convinient count\n",
    "    split_question = row['Clean Question'].split(' ')\n",
    "    # delete from list any word which length less than 6 \n",
    "    split_question = [word for word in split_question if len(word) > 5]\n",
    "    # count question word repeats\n",
    "    for word in split_question:\n",
    "        # for each word in row count it's frequency and frequency of it's high and low values\n",
    "        if word in freq_dict:\n",
    "            freq_dict[word][0] += 1\n",
    "        else:\n",
    "            freq_dict[word] = [1, 0, 0]\n",
    "        if row['High Value'] == 1:\n",
    "            freq_dict[word][1] += 1\n",
    "        else:\n",
    "            freq_dict[word][2] += 1\n",
    "\n",
    "jeopardy.apply(count_terms_freq, axis=1)\n",
    "\n",
    "popular_terms = {k: v for k, v in sorted(freq_dict.items(), key=lambda item: item[1].copy(), reverse=True) if v[0] > 1000}.copy()\n",
    "popular_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to repeat our sci-square calculations for list of popular words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'called': [5461, 1712, 3749, 24.789, 6.396502041100799e-07],\n",
       " 'country': [4868, 1391, 3477, 0.162, 0.6870214064786846],\n",
       " 'became': [3162, 915, 2247, 0.605, 0.4366797022481044],\n",
       " 'played': [3011, 773, 2238, 10.352, 0.0012932490489544497],\n",
       " 'president': [3010, 845, 2165, 0.086, 0.7690485090028965],\n",
       " 'before': [2909, 787, 2122, 2.276, 0.13137471169049217],\n",
       " 'american': [2837, 925, 1912, 25.732, 3.9230643888072246e-07],\n",
       " 'capital': [2772, 803, 1969, 0.584, 0.44466144233485827],\n",
       " 'famous': [2497, 721, 1776, 0.386, 0.5341917767705773],\n",
       " 'french': [2488, 943, 1545, 112.679, 2.536550638160169e-26],\n",
       " 'targetblankherea': [2469, 1065, 1404, 267.189, 4.650186459218781e-60],\n",
       " 'island': [2445, 771, 1674, 12.486, 0.00040997773350746024],\n",
       " 'people': [2224, 603, 1621, 1.58, 0.2087349403944424],\n",
       " 'during': [2000, 563, 1437, 0.027, 0.8705216675424382],\n",
       " 'national': [1976, 571, 1405, 0.33, 0.5654288517992552],\n",
       " 'british': [1947, 657, 1290, 28.283, 1.047921947671791e-07],\n",
       " 'largest': [1943, 481, 1462, 12.123, 0.0004980320506931184],\n",
       " 'century': [1820, 642, 1178, 43.443, 4.365391335034222e-11],\n",
       " 'little': [1812, 480, 1332, 2.971, 0.08479354406781597],\n",
       " 'company': [1798, 498, 1300, 0.337, 0.5615856949505522],\n",
       " 'around': [1797, 530, 1267, 1.231, 0.26711730522377386],\n",
       " 'character': [1755, 510, 1245, 0.481, 0.4881014082237538],\n",
       " 'author': [1692, 644, 1048, 79.201, 5.611408626881465e-19],\n",
       " 'between': [1668, 540, 1128, 13.545, 0.000232873067591866],\n",
       " 'targetblankthisa': [1623, 790, 833, 331.5, 4.530627524279891e-74],\n",
       " 'series': [1619, 399, 1220, 10.74, 0.0010486421402395613],\n",
       " 'meaning': [1570, 580, 990, 57.588, 3.2323425443197446e-14],\n",
       " 'family': [1537, 482, 1055, 7.024, 0.00804283554143223],\n",
       " 'founded': [1486, 482, 1004, 12.439, 0.00042056476395803166],\n",
       " 'include': [1409, 360, 1049, 5.304, 0.021276710634246524],\n",
       " 'states': [1375, 366, 1009, 1.949, 0.1627353968526874],\n",
       " 'number': [1316, 330, 986, 6.799, 0.009122116228683377],\n",
       " 'million': [1308, 334, 974, 4.977, 0.02568809922056132],\n",
       " 'musical': [1307, 413, 894, 6.948, 0.008390015629485085],\n",
       " 'school': [1298, 396, 902, 3.079, 0.07930636916366753],\n",
       " 'popular': [1286, 341, 945, 2.048, 0.15241025178218237],\n",
       " 'english': [1279, 424, 855, 14.741, 0.00012332642188547744],\n",
       " 'museum': [1270, 336, 934, 2.159, 0.14174797624496738],\n",
       " 'because': [1269, 365, 904, 0.126, 0.7228065793754511],\n",
       " 'classic': [1259, 334, 925, 1.977, 0.15972558058188507],\n",
       " 'through': [1239, 378, 861, 2.939, 0.08645876912673285],\n",
       " 'reports': [1235, 539, 696, 142.984, 5.9262631355130054e-33],\n",
       " 'university': [1213, 365, 848, 1.886, 0.1696522784134231],\n",
       " 'countrys': [1135, 259, 876, 16.884, 3.9743321508823615e-05],\n",
       " 'george': [1129, 336, 793, 1.164, 0.28062146382077996],\n",
       " 'person': [1095, 275, 820, 5.524, 0.01875243450222625],\n",
       " 'father': [1092, 338, 754, 3.744, 0.05298168428556335],\n",
       " 'german': [1072, 427, 645, 70.065, 5.737360709788552e-17],\n",
       " 'created': [1037, 307, 730, 0.851, 0.3563371797534375],\n",
       " 'leader': [1031, 339, 692, 10.592, 0.001135640735471576],\n",
       " 'america': [1029, 283, 746, 0.334, 0.563267868758309],\n",
       " 'william': [1024, 319, 705, 4.064, 0.04381226181129773],\n",
       " 'former': [1020, 303, 717, 0.973, 0.3238615962514762],\n",
       " 'general': [1005, 304, 701, 1.853, 0.17342761837050785],\n",
       " 'italian': [1004, 423, 581, 94.437, 2.530559476941658e-22],\n",
       " 'second': [1004, 296, 708, 0.675, 0.41143187099002176]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_terms_chisq = popular_terms.copy()\n",
    "\n",
    "# for every key in dict\n",
    "for key in popular_terms_chisq.keys():\n",
    "    # count sum of each dict element\n",
    "    total = sum(popular_terms_chisq[key][1:])\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    # count expected high and low values for each word\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    # count observed high and low values for each word\n",
    "    observed = np.array([popular_terms_chisq[key][1], popular_terms_chisq[key][2]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    popular_terms_chisq[key].append(round(chisquare(observed, expected)[0], 3))\n",
    "    popular_terms_chisq[key].append(chisquare(observed, expected)[1])\n",
    "\n",
    "popular_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort values in dictionary according to their chisquare value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reports': [1235, 539, 696, 142.984, 5.9262631355130054e-33],\n",
       " 'french': [2488, 943, 1545, 112.679, 2.536550638160169e-26],\n",
       " 'italian': [1004, 423, 581, 94.437, 2.530559476941658e-22],\n",
       " 'author': [1692, 644, 1048, 79.201, 5.611408626881465e-19],\n",
       " 'german': [1072, 427, 645, 70.065, 5.737360709788552e-17],\n",
       " 'meaning': [1570, 580, 990, 57.588, 3.2323425443197446e-14],\n",
       " 'century': [1820, 642, 1178, 43.443, 4.365391335034222e-11],\n",
       " 'british': [1947, 657, 1290, 28.283, 1.047921947671791e-07],\n",
       " 'american': [2837, 925, 1912, 25.732, 3.9230643888072246e-07],\n",
       " 'called': [5461, 1712, 3749, 24.789, 6.396502041100799e-07],\n",
       " 'countrys': [1135, 259, 876, 16.884, 3.9743321508823615e-05],\n",
       " 'english': [1279, 424, 855, 14.741, 0.00012332642188547744],\n",
       " 'between': [1668, 540, 1128, 13.545, 0.000232873067591866],\n",
       " 'island': [2445, 771, 1674, 12.486, 0.00040997773350746024],\n",
       " 'founded': [1486, 482, 1004, 12.439, 0.00042056476395803166],\n",
       " 'largest': [1943, 481, 1462, 12.123, 0.0004980320506931184],\n",
       " 'series': [1619, 399, 1220, 10.74, 0.0010486421402395613],\n",
       " 'leader': [1031, 339, 692, 10.592, 0.001135640735471576],\n",
       " 'played': [3011, 773, 2238, 10.352, 0.0012932490489544497],\n",
       " 'family': [1537, 482, 1055, 7.024, 0.00804283554143223],\n",
       " 'musical': [1307, 413, 894, 6.948, 0.008390015629485085],\n",
       " 'number': [1316, 330, 986, 6.799, 0.009122116228683377],\n",
       " 'person': [1095, 275, 820, 5.524, 0.01875243450222625],\n",
       " 'include': [1409, 360, 1049, 5.304, 0.021276710634246524],\n",
       " 'million': [1308, 334, 974, 4.977, 0.02568809922056132],\n",
       " 'william': [1024, 319, 705, 4.064, 0.04381226181129773],\n",
       " 'father': [1092, 338, 754, 3.744, 0.05298168428556335],\n",
       " 'school': [1298, 396, 902, 3.079, 0.07930636916366753],\n",
       " 'little': [1812, 480, 1332, 2.971, 0.08479354406781597],\n",
       " 'through': [1239, 378, 861, 2.939, 0.08645876912673285],\n",
       " 'before': [2909, 787, 2122, 2.276, 0.13137471169049217],\n",
       " 'museum': [1270, 336, 934, 2.159, 0.14174797624496738],\n",
       " 'popular': [1286, 341, 945, 2.048, 0.15241025178218237],\n",
       " 'classic': [1259, 334, 925, 1.977, 0.15972558058188507],\n",
       " 'states': [1375, 366, 1009, 1.949, 0.1627353968526874],\n",
       " 'university': [1213, 365, 848, 1.886, 0.1696522784134231],\n",
       " 'general': [1005, 304, 701, 1.853, 0.17342761837050785],\n",
       " 'people': [2224, 603, 1621, 1.58, 0.2087349403944424],\n",
       " 'around': [1797, 530, 1267, 1.231, 0.26711730522377386],\n",
       " 'george': [1129, 336, 793, 1.164, 0.28062146382077996],\n",
       " 'former': [1020, 303, 717, 0.973, 0.3238615962514762],\n",
       " 'created': [1037, 307, 730, 0.851, 0.3563371797534375],\n",
       " 'second': [1004, 296, 708, 0.675, 0.41143187099002176],\n",
       " 'became': [3162, 915, 2247, 0.605, 0.4366797022481044],\n",
       " 'capital': [2772, 803, 1969, 0.584, 0.44466144233485827],\n",
       " 'character': [1755, 510, 1245, 0.481, 0.4881014082237538],\n",
       " 'famous': [2497, 721, 1776, 0.386, 0.5341917767705773],\n",
       " 'company': [1798, 498, 1300, 0.337, 0.5615856949505522],\n",
       " 'america': [1029, 283, 746, 0.334, 0.563267868758309],\n",
       " 'national': [1976, 571, 1405, 0.33, 0.5654288517992552],\n",
       " 'country': [4868, 1391, 3477, 0.162, 0.6870214064786846],\n",
       " 'because': [1269, 365, 904, 0.126, 0.7228065793754511],\n",
       " 'president': [3010, 845, 2165, 0.086, 0.7690485090028965],\n",
       " 'during': [2000, 563, 1437, 0.027, 0.8705216675424382]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort word according to their chi-square value\n",
    "popular_terms_chisq = {k: v for k, v in sorted(popular_terms_chisq.items(), key=lambda item: item[1][3], reverse=True)}\n",
    "# delete wrong words\n",
    "del popular_terms_chisq['targetblankthisa']\n",
    "del popular_terms_chisq['targetblankherea']\n",
    "popular_terms_chisq = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert this dictionary to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Frequency</th>\n",
       "      <th>High Value Freq</th>\n",
       "      <th>Low Value Freq</th>\n",
       "      <th>Chi-Square</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reports</th>\n",
       "      <td>1235.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>142.984</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>2488.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>112.679</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>1004.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>94.437</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>1692.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>79.201</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german</th>\n",
       "      <td>1072.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>70.065</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaning</th>\n",
       "      <td>1570.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>57.588</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>century</th>\n",
       "      <td>1820.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>43.443</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>1947.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>28.283</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>american</th>\n",
       "      <td>2837.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>25.732</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>called</th>\n",
       "      <td>5461.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>3749.0</td>\n",
       "      <td>24.789</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>countrys</th>\n",
       "      <td>1135.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>16.884</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>14.741</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>between</th>\n",
       "      <td>1668.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>13.545</td>\n",
       "      <td>0.00023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>island</th>\n",
       "      <td>2445.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1674.0</td>\n",
       "      <td>12.486</td>\n",
       "      <td>0.00041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founded</th>\n",
       "      <td>1486.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>12.439</td>\n",
       "      <td>0.00042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>largest</th>\n",
       "      <td>1943.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>12.123</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series</th>\n",
       "      <td>1619.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>10.740</td>\n",
       "      <td>0.00105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leader</th>\n",
       "      <td>1031.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>10.592</td>\n",
       "      <td>0.00114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>played</th>\n",
       "      <td>3011.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>10.352</td>\n",
       "      <td>0.00129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>1537.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>7.024</td>\n",
       "      <td>0.00804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musical</th>\n",
       "      <td>1307.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>6.948</td>\n",
       "      <td>0.00839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>1316.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>6.799</td>\n",
       "      <td>0.00912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>1095.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>5.524</td>\n",
       "      <td>0.01875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>include</th>\n",
       "      <td>1409.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>5.304</td>\n",
       "      <td>0.02128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>1308.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>4.977</td>\n",
       "      <td>0.02569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>william</th>\n",
       "      <td>1024.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>4.064</td>\n",
       "      <td>0.04381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father</th>\n",
       "      <td>1092.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>3.744</td>\n",
       "      <td>0.05298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>1298.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.07931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>1812.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>2.971</td>\n",
       "      <td>0.08479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>through</th>\n",
       "      <td>1239.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>2.939</td>\n",
       "      <td>0.08646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>before</th>\n",
       "      <td>2909.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>2.276</td>\n",
       "      <td>0.13137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>museum</th>\n",
       "      <td>1270.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>2.159</td>\n",
       "      <td>0.14175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>1286.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2.048</td>\n",
       "      <td>0.15241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classic</th>\n",
       "      <td>1259.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1.977</td>\n",
       "      <td>0.15973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>states</th>\n",
       "      <td>1375.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1.949</td>\n",
       "      <td>0.16274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>university</th>\n",
       "      <td>1213.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>1.886</td>\n",
       "      <td>0.16965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1.853</td>\n",
       "      <td>0.17343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>2224.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>1.580</td>\n",
       "      <td>0.20873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>around</th>\n",
       "      <td>1797.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>1.231</td>\n",
       "      <td>0.26712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>george</th>\n",
       "      <td>1129.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>1.164</td>\n",
       "      <td>0.28062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>former</th>\n",
       "      <td>1020.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.32386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>1037.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.35634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>1004.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.41143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>became</th>\n",
       "      <td>3162.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.43668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital</th>\n",
       "      <td>2772.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.44466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>1755.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.48810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famous</th>\n",
       "      <td>2497.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.53419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>1798.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.56159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america</th>\n",
       "      <td>1029.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.56327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>1976.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.56543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>4868.0</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>3477.0</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.68702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>1269.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.72281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>3010.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2165.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.76905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>during</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.87052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total Frequency  High Value Freq  Low Value Freq  Chi-Square  \\\n",
       "reports              1235.0            539.0           696.0     142.984   \n",
       "french               2488.0            943.0          1545.0     112.679   \n",
       "italian              1004.0            423.0           581.0      94.437   \n",
       "author               1692.0            644.0          1048.0      79.201   \n",
       "german               1072.0            427.0           645.0      70.065   \n",
       "meaning              1570.0            580.0           990.0      57.588   \n",
       "century              1820.0            642.0          1178.0      43.443   \n",
       "british              1947.0            657.0          1290.0      28.283   \n",
       "american             2837.0            925.0          1912.0      25.732   \n",
       "called               5461.0           1712.0          3749.0      24.789   \n",
       "countrys             1135.0            259.0           876.0      16.884   \n",
       "english              1279.0            424.0           855.0      14.741   \n",
       "between              1668.0            540.0          1128.0      13.545   \n",
       "island               2445.0            771.0          1674.0      12.486   \n",
       "founded              1486.0            482.0          1004.0      12.439   \n",
       "largest              1943.0            481.0          1462.0      12.123   \n",
       "series               1619.0            399.0          1220.0      10.740   \n",
       "leader               1031.0            339.0           692.0      10.592   \n",
       "played               3011.0            773.0          2238.0      10.352   \n",
       "family               1537.0            482.0          1055.0       7.024   \n",
       "musical              1307.0            413.0           894.0       6.948   \n",
       "number               1316.0            330.0           986.0       6.799   \n",
       "person               1095.0            275.0           820.0       5.524   \n",
       "include              1409.0            360.0          1049.0       5.304   \n",
       "million              1308.0            334.0           974.0       4.977   \n",
       "william              1024.0            319.0           705.0       4.064   \n",
       "father               1092.0            338.0           754.0       3.744   \n",
       "school               1298.0            396.0           902.0       3.079   \n",
       "little               1812.0            480.0          1332.0       2.971   \n",
       "through              1239.0            378.0           861.0       2.939   \n",
       "before               2909.0            787.0          2122.0       2.276   \n",
       "museum               1270.0            336.0           934.0       2.159   \n",
       "popular              1286.0            341.0           945.0       2.048   \n",
       "classic              1259.0            334.0           925.0       1.977   \n",
       "states               1375.0            366.0          1009.0       1.949   \n",
       "university           1213.0            365.0           848.0       1.886   \n",
       "general              1005.0            304.0           701.0       1.853   \n",
       "people               2224.0            603.0          1621.0       1.580   \n",
       "around               1797.0            530.0          1267.0       1.231   \n",
       "george               1129.0            336.0           793.0       1.164   \n",
       "former               1020.0            303.0           717.0       0.973   \n",
       "created              1037.0            307.0           730.0       0.851   \n",
       "second               1004.0            296.0           708.0       0.675   \n",
       "became               3162.0            915.0          2247.0       0.605   \n",
       "capital              2772.0            803.0          1969.0       0.584   \n",
       "character            1755.0            510.0          1245.0       0.481   \n",
       "famous               2497.0            721.0          1776.0       0.386   \n",
       "company              1798.0            498.0          1300.0       0.337   \n",
       "america              1029.0            283.0           746.0       0.334   \n",
       "national             1976.0            571.0          1405.0       0.330   \n",
       "country              4868.0           1391.0          3477.0       0.162   \n",
       "because              1269.0            365.0           904.0       0.126   \n",
       "president            3010.0            845.0          2165.0       0.086   \n",
       "during               2000.0            563.0          1437.0       0.027   \n",
       "\n",
       "            P-value  \n",
       "reports     0.00000  \n",
       "french      0.00000  \n",
       "italian     0.00000  \n",
       "author      0.00000  \n",
       "german      0.00000  \n",
       "meaning     0.00000  \n",
       "century     0.00000  \n",
       "british     0.00000  \n",
       "american    0.00000  \n",
       "called      0.00000  \n",
       "countrys    0.00004  \n",
       "english     0.00012  \n",
       "between     0.00023  \n",
       "island      0.00041  \n",
       "founded     0.00042  \n",
       "largest     0.00050  \n",
       "series      0.00105  \n",
       "leader      0.00114  \n",
       "played      0.00129  \n",
       "family      0.00804  \n",
       "musical     0.00839  \n",
       "number      0.00912  \n",
       "person      0.01875  \n",
       "include     0.02128  \n",
       "million     0.02569  \n",
       "william     0.04381  \n",
       "father      0.05298  \n",
       "school      0.07931  \n",
       "little      0.08479  \n",
       "through     0.08646  \n",
       "before      0.13137  \n",
       "museum      0.14175  \n",
       "popular     0.15241  \n",
       "classic     0.15973  \n",
       "states      0.16274  \n",
       "university  0.16965  \n",
       "general     0.17343  \n",
       "people      0.20873  \n",
       "around      0.26712  \n",
       "george      0.28062  \n",
       "former      0.32386  \n",
       "created     0.35634  \n",
       "second      0.41143  \n",
       "became      0.43668  \n",
       "capital     0.44466  \n",
       "character   0.48810  \n",
       "famous      0.53419  \n",
       "company     0.56159  \n",
       "america     0.56327  \n",
       "national    0.56543  \n",
       "country     0.68702  \n",
       "because     0.72281  \n",
       "president   0.76905  \n",
       "during      0.87052  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns=1000\n",
    "\n",
    "# make a dataframe from dict and transpose in\n",
    "popular_terms_df = pd.DataFrame(popular_terms_chisq, index=['Total Frequency', 'High Value Freq', 'Low Value Freq', 'Chi-Square', 'P-value'])\n",
    "popular_terms_df = popular_terms_df.transpose()\n",
    "\n",
    "# function for rounding values in dataframe\n",
    "def round_value(value):\n",
    "    return round(value, 5)\n",
    "\n",
    "popular_terms_df['P-value'] = popular_terms_df['P-value'].apply(round_value)\n",
    "popular_terms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some words like *reports*, *french*, *italian*, *author*, etc can be met in high value questions more often than it's expected. \n",
    "Let's filter this words thus only words which chi-square value significally higher than p-value left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Frequency</th>\n",
       "      <th>High Value Freq</th>\n",
       "      <th>Low Value Freq</th>\n",
       "      <th>Chi-Square</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reports</th>\n",
       "      <td>1235.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>142.984</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>2488.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>112.679</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>1004.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>94.437</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>1692.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>79.201</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german</th>\n",
       "      <td>1072.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>70.065</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaning</th>\n",
       "      <td>1570.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>57.588</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>century</th>\n",
       "      <td>1820.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>43.443</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>1947.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>28.283</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>american</th>\n",
       "      <td>2837.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>25.732</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>called</th>\n",
       "      <td>5461.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>3749.0</td>\n",
       "      <td>24.789</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>countrys</th>\n",
       "      <td>1135.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>16.884</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>14.741</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>between</th>\n",
       "      <td>1668.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>13.545</td>\n",
       "      <td>0.00023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>island</th>\n",
       "      <td>2445.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1674.0</td>\n",
       "      <td>12.486</td>\n",
       "      <td>0.00041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founded</th>\n",
       "      <td>1486.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>12.439</td>\n",
       "      <td>0.00042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>largest</th>\n",
       "      <td>1943.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>12.123</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series</th>\n",
       "      <td>1619.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>10.740</td>\n",
       "      <td>0.00105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leader</th>\n",
       "      <td>1031.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>10.592</td>\n",
       "      <td>0.00114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>played</th>\n",
       "      <td>3011.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>10.352</td>\n",
       "      <td>0.00129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>1537.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>7.024</td>\n",
       "      <td>0.00804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musical</th>\n",
       "      <td>1307.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>6.948</td>\n",
       "      <td>0.00839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>1316.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>6.799</td>\n",
       "      <td>0.00912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>1095.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>5.524</td>\n",
       "      <td>0.01875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>include</th>\n",
       "      <td>1409.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>5.304</td>\n",
       "      <td>0.02128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>1308.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>4.977</td>\n",
       "      <td>0.02569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>william</th>\n",
       "      <td>1024.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>4.064</td>\n",
       "      <td>0.04381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father</th>\n",
       "      <td>1092.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>3.744</td>\n",
       "      <td>0.05298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>1298.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.07931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>1812.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>2.971</td>\n",
       "      <td>0.08479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>through</th>\n",
       "      <td>1239.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>2.939</td>\n",
       "      <td>0.08646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>before</th>\n",
       "      <td>2909.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>2.276</td>\n",
       "      <td>0.13137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>museum</th>\n",
       "      <td>1270.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>2.159</td>\n",
       "      <td>0.14175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>1286.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2.048</td>\n",
       "      <td>0.15241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classic</th>\n",
       "      <td>1259.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1.977</td>\n",
       "      <td>0.15973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>states</th>\n",
       "      <td>1375.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1.949</td>\n",
       "      <td>0.16274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>university</th>\n",
       "      <td>1213.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>1.886</td>\n",
       "      <td>0.16965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1.853</td>\n",
       "      <td>0.17343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>2224.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>1.580</td>\n",
       "      <td>0.20873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>around</th>\n",
       "      <td>1797.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>1.231</td>\n",
       "      <td>0.26712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>george</th>\n",
       "      <td>1129.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>1.164</td>\n",
       "      <td>0.28062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>former</th>\n",
       "      <td>1020.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.32386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>1037.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.35634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total Frequency  High Value Freq  Low Value Freq  Chi-Square  \\\n",
       "reports              1235.0            539.0           696.0     142.984   \n",
       "french               2488.0            943.0          1545.0     112.679   \n",
       "italian              1004.0            423.0           581.0      94.437   \n",
       "author               1692.0            644.0          1048.0      79.201   \n",
       "german               1072.0            427.0           645.0      70.065   \n",
       "meaning              1570.0            580.0           990.0      57.588   \n",
       "century              1820.0            642.0          1178.0      43.443   \n",
       "british              1947.0            657.0          1290.0      28.283   \n",
       "american             2837.0            925.0          1912.0      25.732   \n",
       "called               5461.0           1712.0          3749.0      24.789   \n",
       "countrys             1135.0            259.0           876.0      16.884   \n",
       "english              1279.0            424.0           855.0      14.741   \n",
       "between              1668.0            540.0          1128.0      13.545   \n",
       "island               2445.0            771.0          1674.0      12.486   \n",
       "founded              1486.0            482.0          1004.0      12.439   \n",
       "largest              1943.0            481.0          1462.0      12.123   \n",
       "series               1619.0            399.0          1220.0      10.740   \n",
       "leader               1031.0            339.0           692.0      10.592   \n",
       "played               3011.0            773.0          2238.0      10.352   \n",
       "family               1537.0            482.0          1055.0       7.024   \n",
       "musical              1307.0            413.0           894.0       6.948   \n",
       "number               1316.0            330.0           986.0       6.799   \n",
       "person               1095.0            275.0           820.0       5.524   \n",
       "include              1409.0            360.0          1049.0       5.304   \n",
       "million              1308.0            334.0           974.0       4.977   \n",
       "william              1024.0            319.0           705.0       4.064   \n",
       "father               1092.0            338.0           754.0       3.744   \n",
       "school               1298.0            396.0           902.0       3.079   \n",
       "little               1812.0            480.0          1332.0       2.971   \n",
       "through              1239.0            378.0           861.0       2.939   \n",
       "before               2909.0            787.0          2122.0       2.276   \n",
       "museum               1270.0            336.0           934.0       2.159   \n",
       "popular              1286.0            341.0           945.0       2.048   \n",
       "classic              1259.0            334.0           925.0       1.977   \n",
       "states               1375.0            366.0          1009.0       1.949   \n",
       "university           1213.0            365.0           848.0       1.886   \n",
       "general              1005.0            304.0           701.0       1.853   \n",
       "people               2224.0            603.0          1621.0       1.580   \n",
       "around               1797.0            530.0          1267.0       1.231   \n",
       "george               1129.0            336.0           793.0       1.164   \n",
       "former               1020.0            303.0           717.0       0.973   \n",
       "created              1037.0            307.0           730.0       0.851   \n",
       "\n",
       "            P-value  \n",
       "reports     0.00000  \n",
       "french      0.00000  \n",
       "italian     0.00000  \n",
       "author      0.00000  \n",
       "german      0.00000  \n",
       "meaning     0.00000  \n",
       "century     0.00000  \n",
       "british     0.00000  \n",
       "american    0.00000  \n",
       "called      0.00000  \n",
       "countrys    0.00004  \n",
       "english     0.00012  \n",
       "between     0.00023  \n",
       "island      0.00041  \n",
       "founded     0.00042  \n",
       "largest     0.00050  \n",
       "series      0.00105  \n",
       "leader      0.00114  \n",
       "played      0.00129  \n",
       "family      0.00804  \n",
       "musical     0.00839  \n",
       "number      0.00912  \n",
       "person      0.01875  \n",
       "include     0.02128  \n",
       "million     0.02569  \n",
       "william     0.04381  \n",
       "father      0.05298  \n",
       "school      0.07931  \n",
       "little      0.08479  \n",
       "through     0.08646  \n",
       "before      0.13137  \n",
       "museum      0.14175  \n",
       "popular     0.15241  \n",
       "classic     0.15973  \n",
       "states      0.16274  \n",
       "university  0.16965  \n",
       "general     0.17343  \n",
       "people      0.20873  \n",
       "around      0.26712  \n",
       "george      0.28062  \n",
       "former      0.32386  \n",
       "created     0.35634  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_terms_df.loc[popular_terms_df['Chi-Square'] > 2*popular_terms_df['P-value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a lot of popular words with high frequency and high value are related to countries like America, England, German, France, geography, history, education and arts. Let's also look more close on *Category* column of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BEFORE & AFTER             547\n",
       "SCIENCE                    519\n",
       "LITERATURE                 496\n",
       "AMERICAN HISTORY           418\n",
       "POTPOURRI                  401\n",
       "WORLD HISTORY              377\n",
       "WORD ORIGINS               371\n",
       "COLLEGES & UNIVERSITIES    351\n",
       "HISTORY                    349\n",
       "SPORTS                     342\n",
       "U.S. CITIES                339\n",
       "WORLD GEOGRAPHY            338\n",
       "BODIES OF WATER            327\n",
       "ANIMALS                    324\n",
       "STATE CAPITALS             314\n",
       "BUSINESS & INDUSTRY        311\n",
       "ISLANDS                    301\n",
       "WORLD CAPITALS             300\n",
       "U.S. GEOGRAPHY             299\n",
       "RELIGION                   297\n",
       "SHAKESPEARE                294\n",
       "OPERA                      294\n",
       "LANGUAGES                  284\n",
       "BALLET                     282\n",
       "TELEVISION                 281\n",
       "FICTIONAL CHARACTERS       280\n",
       "TRANSPORTATION             279\n",
       "PEOPLE                     279\n",
       "RHYME TIME                 279\n",
       "STUPID ANSWERS             270\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['Category'].value_counts()[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our word analysis has confirmed. Geography, history, education and arts are quite popular themes in Jeopardy's questions. Espesially popular America related questions. Well, that's not surprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShowNumber</th>\n",
       "      <th>AirDate</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value, $</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Clean Question</th>\n",
       "      <th>Clean Answer</th>\n",
       "      <th>Answer in Question</th>\n",
       "      <th>Questions Overlap</th>\n",
       "      <th>High Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137409</th>\n",
       "      <td>2</td>\n",
       "      <td>1984-09-11</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>STATE CAPITALS</td>\n",
       "      <td>400</td>\n",
       "      <td>It actually &lt;u&gt;is&lt;/u&gt; 5,280 feet above sea level</td>\n",
       "      <td>Denver</td>\n",
       "      <td>it actually uisu 5280 feet above sea level</td>\n",
       "      <td>denver</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164716</th>\n",
       "      <td>3</td>\n",
       "      <td>1984-09-12</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>WORLD OF FOOD</td>\n",
       "      <td>800</td>\n",
       "      <td>French for \"sour wine\", one variety is literal...</td>\n",
       "      <td>vinegar</td>\n",
       "      <td>french for sour wine one variety is literally ...</td>\n",
       "      <td>vinegar</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70463</th>\n",
       "      <td>4</td>\n",
       "      <td>1984-09-13</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>STATE CAPITALS</td>\n",
       "      <td>600</td>\n",
       "      <td>1 of 4 state capitals that end in word \"City\"</td>\n",
       "      <td>(1 of) Salt Lake City, Oklahoma City, Jefferso...</td>\n",
       "      <td>1 of 4 state capitals that end in word city</td>\n",
       "      <td>1 of salt lake city oklahoma city jefferson ci...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127871</th>\n",
       "      <td>5</td>\n",
       "      <td>1984-09-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>AMERICAN LITERATURE</td>\n",
       "      <td>200</td>\n",
       "      <td>Lincoln called it \"the book that caused the bi...</td>\n",
       "      <td>Uncle Tom's Cabin</td>\n",
       "      <td>lincoln called it the book that caused the big...</td>\n",
       "      <td>uncle toms cabin</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127905</th>\n",
       "      <td>5</td>\n",
       "      <td>1984-09-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>SHAKESPEARE</td>\n",
       "      <td>600</td>\n",
       "      <td>Battle of the sexes on which musical \"Kiss Me ...</td>\n",
       "      <td>The Taming of the Shrew</td>\n",
       "      <td>battle of the sexes on which musical kiss me k...</td>\n",
       "      <td>the taming of the shrew</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105934</th>\n",
       "      <td>6300</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE TRUTH LIES THEREIN</td>\n",
       "      <td>200</td>\n",
       "      <td>Symbol for the second-lightest element</td>\n",
       "      <td>He</td>\n",
       "      <td>symbol for the second-lightest element</td>\n",
       "      <td>he</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105944</th>\n",
       "      <td>6300</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>STUPID ANSWERS</td>\n",
       "      <td>600</td>\n",
       "      <td>This was first imprinted in black on individua...</td>\n",
       "      <td>M</td>\n",
       "      <td>this was first imprinted in black on individua...</td>\n",
       "      <td>m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105946</th>\n",
       "      <td>6300</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE TRUTH LIES THEREIN</td>\n",
       "      <td>600</td>\n",
       "      <td>Old school CBS history show:  \"You Are\" this</td>\n",
       "      <td>There</td>\n",
       "      <td>old school cbs history show  you are this</td>\n",
       "      <td>there</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105947</th>\n",
       "      <td>6300</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>VISITING THE CITY</td>\n",
       "      <td>800</td>\n",
       "      <td>There's a great opera house on Bennelong Point...</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>theres a great opera house on bennelong point ...</td>\n",
       "      <td>sydney</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105948</th>\n",
       "      <td>6300</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>PANTS</td>\n",
       "      <td>1400</td>\n",
       "      <td>Tight-fitting pants patterned after those worn...</td>\n",
       "      <td>toreador pants</td>\n",
       "      <td>tight-fitting pants patterned after those worn...</td>\n",
       "      <td>toreador pants</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139202 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ShowNumber    AirDate             Round                Category  \\\n",
       "137409           2 1984-09-11         Jeopardy!          STATE CAPITALS   \n",
       "164716           3 1984-09-12  Double Jeopardy!           WORLD OF FOOD   \n",
       "70463            4 1984-09-13  Double Jeopardy!          STATE CAPITALS   \n",
       "127871           5 1984-09-14         Jeopardy!     AMERICAN LITERATURE   \n",
       "127905           5 1984-09-14  Double Jeopardy!             SHAKESPEARE   \n",
       "...            ...        ...               ...                     ...   \n",
       "105934        6300 2012-01-27         Jeopardy!  THE TRUTH LIES THEREIN   \n",
       "105944        6300 2012-01-27         Jeopardy!          STUPID ANSWERS   \n",
       "105946        6300 2012-01-27         Jeopardy!  THE TRUTH LIES THEREIN   \n",
       "105947        6300 2012-01-27         Jeopardy!       VISITING THE CITY   \n",
       "105948        6300 2012-01-27         Jeopardy!                   PANTS   \n",
       "\n",
       "        Value, $                                           Question  \\\n",
       "137409       400   It actually <u>is</u> 5,280 feet above sea level   \n",
       "164716       800  French for \"sour wine\", one variety is literal...   \n",
       "70463        600      1 of 4 state capitals that end in word \"City\"   \n",
       "127871       200  Lincoln called it \"the book that caused the bi...   \n",
       "127905       600  Battle of the sexes on which musical \"Kiss Me ...   \n",
       "...          ...                                                ...   \n",
       "105934       200             Symbol for the second-lightest element   \n",
       "105944       600  This was first imprinted in black on individua...   \n",
       "105946       600       Old school CBS history show:  \"You Are\" this   \n",
       "105947       800  There's a great opera house on Bennelong Point...   \n",
       "105948      1400  Tight-fitting pants patterned after those worn...   \n",
       "\n",
       "                                                   Answer  \\\n",
       "137409                                             Denver   \n",
       "164716                                            vinegar   \n",
       "70463   (1 of) Salt Lake City, Oklahoma City, Jefferso...   \n",
       "127871                                  Uncle Tom's Cabin   \n",
       "127905                            The Taming of the Shrew   \n",
       "...                                                   ...   \n",
       "105934                                                 He   \n",
       "105944                                                  M   \n",
       "105946                                              There   \n",
       "105947                                             Sydney   \n",
       "105948                                     toreador pants   \n",
       "\n",
       "                                           Clean Question  \\\n",
       "137409         it actually uisu 5280 feet above sea level   \n",
       "164716  french for sour wine one variety is literally ...   \n",
       "70463         1 of 4 state capitals that end in word city   \n",
       "127871  lincoln called it the book that caused the big...   \n",
       "127905  battle of the sexes on which musical kiss me k...   \n",
       "...                                                   ...   \n",
       "105934             symbol for the second-lightest element   \n",
       "105944  this was first imprinted in black on individua...   \n",
       "105946          old school cbs history show  you are this   \n",
       "105947  theres a great opera house on bennelong point ...   \n",
       "105948  tight-fitting pants patterned after those worn...   \n",
       "\n",
       "                                             Clean Answer  Answer in Question  \\\n",
       "137409                                             denver            0.000000   \n",
       "164716                                            vinegar            0.000000   \n",
       "70463   1 of salt lake city oklahoma city jefferson ci...            0.545455   \n",
       "127871                                   uncle toms cabin            0.000000   \n",
       "127905                            the taming of the shrew            0.500000   \n",
       "...                                                   ...                 ...   \n",
       "105934                                                 he            0.000000   \n",
       "105944                                                  m            0.000000   \n",
       "105946                                              there            0.000000   \n",
       "105947                                             sydney            0.000000   \n",
       "105948                                     toreador pants            0.500000   \n",
       "\n",
       "        Questions Overlap  High Value  \n",
       "137409                1.0           0  \n",
       "164716                1.0           0  \n",
       "70463                 1.0           0  \n",
       "127871                1.0           0  \n",
       "127905                1.0           0  \n",
       "...                   ...         ...  \n",
       "105934                1.0           0  \n",
       "105944                1.0           0  \n",
       "105946                1.0           0  \n",
       "105947                1.0           0  \n",
       "105948                1.0           1  \n",
       "\n",
       "[139202 rows x 12 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[jeopardy['Questions Overlap'] == 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
